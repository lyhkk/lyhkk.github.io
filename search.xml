<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>SWin-Transformer</title>
    <url>/2023/08/10/SWin-Transformer/</url>
    <content><![CDATA[<p><a href="https://github.com/SwinTransformer/Swin-Transformer-Semantic-Segmentation"><strong>github仓库地址</strong></a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ol>
<li>代码是<code>openmmlab</code>用<code>mmcv库</code>和<code>mmseg toolbox</code>实现了训练，验证，测试过程，支持多种语义分割模型，本次实验采用SWin-Transformer为backbone的模型</li>
<li>实验难点：<code>mmcv</code>和<code>mmseg</code>的安装，环境配置</li>
<li>硬件环境：腾讯云租用<code>V100 GPU服务器</code>(特价)，32G显存，10核</li>
</ol>
<h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p><strong>2023.8.8：</strong>先按照现有环境(cuda&#x3D;11.8.0, torch&#x3D;2.0.1)直接装mmcv和mmseg试试看</p>
<blockquote>
<p>目前环境：</p>
<p>mmseg&#x3D;1.1.1<br>mmcv&#x3D;2.0.1<br>mmengine&#x3D;0.8.4(mmengine为mmcv大改之后新增的库，支持很多原来放在mmcv里的接口，比方说train的代码，data_parallel的内容)</p>
<p>官网提供的版本依赖关系：<img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241754.png" alt="image-20230808150904656"></p>
<p>根据官网文档，mmcv和mmseg匹配，但是<code>module not found</code>，因为<code>train</code>的部分已经从mmcv移除</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241756.png" alt="image-20230808151010143"></p>
</blockquote>
<p><strong>2023.8.9：</strong></p>
<blockquote>
<p>找到的适配环境：</p>
<p>mmseg&#x3D;0.11.0</p>
<p>mmcv&#x3D;1.3.0</p>
<p>torch&#x3D;1.7.0</p>
<p>cuda&#x3D;11.0</p>
</blockquote>
<p>如何找到的环境：</p>
<ol>
<li><p>requirements.txt没给出mmcv和mmseg的版本，但源码有mmseg文件夹，进入<code>mmseg/version.py</code>可以得知mmseg需要0.11.0版本，并且需要mmcv满足<code>1.0.4-1.3.0</code>之间</p>
<p>-&gt;mmcv&#x3D;1.3.0，mmseg&#x3D;0.11.0。</p>
</li>
<li><p>因为mmcv包括了一些cuda运算的内容，<strong>mmcv必须与torch、cuda版本匹配，同时也有不支持的python版本</strong></p>
<ol>
<li><p>发现一个html网页(格式为:download.openmmlab.com&#x2F;mmcv&#x2F;dist&#x2F;cu<xxx>&#x2F;torch&lt;x.x.x&gt;&#x2F;index.html，其中xxx和x.x.x代表版本号)可以查找，特定torch和cuda版本下的mmcv的.whl包。</p>
</li>
<li><p>尝试不同版本号，最终找到<a href="https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html">合适的版本</a>为：cuda&#x3D;11.0，torch&#x3D;1.7.0，python&#x3D;3.8。下载.whl包</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241757.png" alt="image-20230810221836793"></p>
</li>
<li><p>重装系统–cuda&#x3D;11.0，再安装mmcv和mmseg。</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241758.png" alt="image-20230810221728646"></p>
</li>
</ol>
</li>
<li><p>安装mmseg: 但不管是pip和open-mmlab提供的mim包，都找不到mmseg&#x3D;0.11.0(太旧)，所以直接把github库给的源码，复制到对应虚拟环境python3.8的packages </p>
</li>
<li><p>安装mmcv: mmcv有mmcv-full, mmcv, mmcv-lite三种，直接pip或mim安装的mmcv包缺少mmseg需要的接口，需要full版本，使用下载的mmcv-full 1.3.0的.whl包，pip安装即可。</p>
</li>
<li><p>PS: 因为我是单GPU训练，它的config文件(configs&#x2F;_base&#x2F;models&#x2F;upernet_swin.py)中有一个地方接口没对好，使用了<code>SyncBN</code>，这个需要手动改为<code>BN</code>，改正就可以跑动了。</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241759.png" alt="image-20230810222549116"></p>
</li>
</ol>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><strong>2023.8.9:训练SWin-B模型</strong></p>
<p>对标：</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241760.png" alt="image-20230810224052923"></p>
<p>开始训练，只加载了预训练模型(github提供)，改动了batch size</p>
<p>(configs&#x2F;swin&#x2F;upernet_swin_base_patch4_window7_512x512_160k_ade20k.py)中的data段改为<strong>samples_per_gpu&#x3D;8</strong>(因为github是8GPUs分布式训练，我只有单GPU，并且开不到16，&#x3D;8时已经占用24G显存)</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241761.png" alt="image-20230810222731182"></p>
<blockquote>
<p>本实验的batch size影响很大，当我samples_per_gpu设为4时，对比作者的log文件，同样15950iterations下</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102241762.png" alt="image-20230810223522211"></p>
</blockquote>
<p><strong>2023.8.10:</strong></p>
<p>跑的好慢！！！应该去跑Swin-S的，参数量少，应该速度会快很多</p>
<p>北京时间22:45，跑到了96k iterations的checkpoint(每16k iterations一次验证), validation结果和github在96k iterations的checkpoint处结果对标：</p>
<p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202308102315467.png" alt="image-20230810225538462"></p>
]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>semantic segmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ STL</title>
    <url>/2023/07/05/C-STL/</url>
    <content><![CDATA[<h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><ol>
<li><p>全称：Standard Template Library,标准模板库</p>
</li>
<li><p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202307061142412.png" alt="image-20230409145131333"></p>
<blockquote>
<p>迭代器是沟通算法和容器的桥梁，容器相当于数据结构，算法根据容器提供的迭代器进行操作 -&gt; 数据结构有了配套的操作</p>
</blockquote>
</li>
</ol>
<h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p><img src="https://lyhkk-1314912494.cos.ap-beijing.myqcloud.com/Project/202307061142269.png" alt="image-20230409145354236"></p>
<blockquote>
<p>容器更像一个类</p>
</blockquote>
<h3 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h3><ol>
<li><p>特点：</p>
<ol>
<li>拥有一段连续的内存空间，因此它能非常好的<code>支持随机访问</code>，即 [] 操作符和 .at()，随机访问快。（优点）</li>
<li>当向其头部或中间插入或删除元素时，为了<code>保持原本的相对次序</code>，插入或删除点之后的所有元素都必须移动，所以<code>插入或删除的效率比较低</code>。（缺点）</li>
<li>在后面插入删除元素最快，此时一般不需要移动内存。（优点）</li>
<li>总结：相当于可拓展的数组（<code>动态数组</code>），随机访问快，在头部和中间插入或删除效率低，但在尾部插入或删除效率高。</li>
</ol>
</li>
<li><p>操作：</p>
<p>1.<code>push_back</code> 在数组的最后添加一个数据</p>
<p>2.pop_back 去掉数组的最后一个数据</p>
<p>3.<code>at</code> 得到编号位置的数据</p>
<p>4.begin 得到数组头的指针</p>
<p>5.end 得到数组的最后一个单元+1的指针</p>
<p>6.front 得到数组头的引用</p>
<p>7.back 得到数组的最后一个单元的引用</p>
<p>8.max_size 得到vector最大可以是多大</p>
<p>9.capacity 当前vector分配的大小</p>
<p>10.<code>size</code> 当前使用数据的大小</p>
<p>11.resize 改变当前使用数据的大小，如果它比当前使用的大，者填充默认值</p>
<p>12.reserve 改变当前vecotr所分配空间的大小</p>
<p>13.erase 删除指针指向的数据项</p>
<p>14.<code>clear</code> 清空当前的vector</p>
<p>15.rbegin 将vector反转后的开始指针返回(其实就是原来的end-1)</p>
<p>16.rend 将vector反转构的结束指针返回(其实就是原来的begin-1)</p>
<p>17.empty 判断vector是否为空</p>
<p>18.swap 与另一个vector交换数据</p>
</li>
<li><p>特性：</p>
<ol>
<li>在动态扩容上，vector动态增加大小时，并不是在原空间之后持续新空间（因为无法保证原空间之后尚有可供配置的空间），而是<code>以原大小的两倍另外配置一块较大的空间，然后将原内容拷贝过来</code>，然后才开始在原内容之后构造新元素，并释放原空间。因此， 对vector的任何操作，<code>一旦引起空间重新配置，指向原vector的所有迭代器就都失效了</code>。</li>
</ol>
</li>
</ol>
<h3 id="deque"><a href="#deque" class="headerlink" title="deque"></a>deque</h3><ol>
<li><p>deque（double-ended queue）是双向开口的连续内存空间（动态将多个连续空间通过指针数组接合在一起），随时可以增加一段新的空间。deque 的最大任务就是<code>在这些分段的连续空间上，维护其整体连续的假象，并提供随机存取的接口</code>。</p>
</li>
<li><p><strong>特点</strong></p>
<ul>
<li><p>一旦要在 deque 的头部和尾部增加新空间，便配置一段定量连续空间，串在整个 deque 的头部或尾部，因此不论在头部或尾部插入元素都十分迅速。 (优点）</p>
</li>
<li><p>在中间部分安插元素则比较费时，因为必须移动其它元素。（缺点）</p>
</li>
<li><p>deque 是 list 和 vector 的折中方案。兼有 list 的优点，也有 vector 随机访问效率高的优点。</p>
</li>
<li><p>总结：支持随机访问，但效率没有 vector 高，在头部和尾部插入或删除效率高，但在中间插入或删除效率低。</p>
</li>
</ul>
</li>
</ol>
<h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><ol>
<li>每个元素最多只出现一次，并且 set 中的元素已经从小到大排好序</li>
<li><strong>特点</strong><ul>
<li>使用红黑树实现，其内部元素依据其值自动排序，每个元素值只能出现一次，不允许重复。</li>
<li>每次插入值的时候，都需要调整红黑树，效率有一定影响。（缺点）</li>
<li>map 和 set 的插入或删除效率比用其他序列容器高，因为对于关联容器来说，不需要做内存拷贝和内存移动。（优点）</li>
<li>总结：由红黑树实现，其内部元素依据其值自动排序，每个元素值只能出现一次，不允许重复，且插入和删除效率比用其他序列容器高。</li>
</ul>
</li>
</ol>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>List 由双向链表（doubly linked list）实现而成，元素<u>存放在堆中</u>，每个元素都是放在一块内存中。没有空间预留习惯，所以<u>每分配一个元素都会从内存中分配，每删除一个元素都会释放它占用的内存</u>。</p>
<p><strong>特点</strong></p>
<ul>
<li>内存空间可以是不连续的，通过指针来进行数据的访问，这个特点使得它的随机存取变得非常没有效率，因此它没有提供 [] 操作符的重载。（缺点）</li>
<li>由于链表的特点，在任意位置的插入和删除效率都较高。（优点）</li>
<li><u>只支持首尾两个元素的直接存取</u>，想获取其他元素（访问时间一样），则需要遍历链表。（缺点）</li>
<li>总结：不支持随机访问，<u>在任意位置的插入和删除效率都较高</u>。</li>
</ul>
<h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><p>map 由红黑树实现，其元素都是 <code>“键值/实值”</code>所形成的一个对组（key&#x2F;value pairs)。</p>
<p>map 主要用于资料一对一映射的情况，map 内部自建一颗红黑树，这颗树具有对数据自动排序的功能，所以在 map 内部所有的数据都是有序的。比如一个班级中，每个学生的学号跟他的姓名就存在着一对一映射的关系。</p>
<p><strong>特点</strong></p>
<ul>
<li>每个元素都有一个键，且只能出现一次，不允许重复。</li>
<li>根据 key 值快速查找记录，查找的复杂度基本是 O(logN)，如果有 1000 个记录，二分查找最多查找 10次(1024)。（优点）</li>
<li>每次插入值的时候，都需要调整红黑树，效率有一定影响。（缺点）</li>
<li>增加和删除节点对迭代器的影响很小，除了那个操作节点，对其他的节点都没有什么影响。（优点）</li>
<li>对于迭代器来说，可以修改实值，而不能修改 key。</li>
<li>总结：元素为键值对，key 和 value 可以是<code>任意你需要的类型</code>，每个元素都有一个键，且只能出现一次，不允许重复，根据 key 快速查找记录。</li>
</ul>
<p><strong>适用场景</strong></p>
<p>适用于需要存储一个数据字典，并要求方便地根据key找value的场景。</p>
<h2 id="iterator"><a href="#iterator" class="headerlink" title="iterator"></a>iterator</h2><ol>
<li><p>迭代器类似指针，指向容器中的某个元素，用-&gt;(如果容器中的元素是pair，可以用it-&gt;first与it-&gt;second访问第一个和第二个值)或者*(元素为一个值)访问指向的元素</p>
</li>
<li><p>容器适配器 stack、queue 和 priority_queue <code>没有</code>迭代器。容器适配器有一些成员函数，可以用来对元素进行访问。</p>
</li>
<li><p>分类：</p>
<ol>
<li>正向：容器类名&lt;&gt;::iterator 迭代器名;</li>
<li>反向：容器类名&lt;&gt;::reverse_iterator 迭代器名;</li>
<li>常量正向：容器类名&lt;&gt;::const_iterator 迭代器名;</li>
<li>常量反向：容器类名&lt;&gt;::const_reverse_iterator 迭代器名;</li>
</ol>
</li>
<li><p>迭代器都可以进行<code>++</code>操作。反向迭代器和正向迭代器的区别在于：</p>
<ul>
<li><p>对正向迭代器进行<code>++</code>操作时，迭代器会指向容器中的后一个元素；</p>
</li>
<li><p>而对反向迭代器进行<code>++</code>操作时，迭代器会指向容器中的前一个元素。</p>
<blockquote>
<p>使用正向&#x2F;反向迭代器写for循环迭代时，要写it !&#x3D; container.end()&#x2F;rend()而不是&lt;&#x3D;，因为反向迭代器的++是反向的，都这么写美观整齐</p>
</blockquote>
</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
